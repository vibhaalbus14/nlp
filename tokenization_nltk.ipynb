{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FxwR0FqWw9C"
      },
      "outputs": [],
      "source": [
        "#!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install spacy\n"
      ],
      "metadata": {
        "id": "8VkxRbJ3X1Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "id": "8tJ9NLfsX6Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text='''hello, i'm Ms.vibha.Studing at DSCE.nder the guidance of Dr.Latha .A.P.Today was a bright day.\n",
        "On Sunday,Bangalore faced torrentious rain that uprooted several trees,created massive havoc at all places.Few accidents were also seen.'''"
      ],
      "metadata": {
        "id": "MTFDkqNxYCy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words1=text.split(' ')\n",
        "words1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lysBMXlLYQHc",
        "outputId": "ef818542-b268-4fbf-c97d-253ecca361ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello,',\n",
              " \"i'm\",\n",
              " 'Ms.vibha.Studing',\n",
              " 'at',\n",
              " 'DSCE.nder',\n",
              " 'the',\n",
              " 'guidance',\n",
              " 'of',\n",
              " 'Dr.Latha',\n",
              " '.A.P.Today',\n",
              " 'was',\n",
              " 'a',\n",
              " 'bright',\n",
              " 'day.\\nOn',\n",
              " 'Sunday,Bangalore',\n",
              " 'faced',\n",
              " 'torrentious',\n",
              " 'rain',\n",
              " 'that',\n",
              " 'uprooted',\n",
              " 'several',\n",
              " 'trees,created',\n",
              " 'massive',\n",
              " 'havoc',\n",
              " 'at',\n",
              " 'all',\n",
              " 'places.Few',\n",
              " 'accidents',\n",
              " 'were',\n",
              " 'also',\n",
              " 'seen.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words2=text.split(\". \")\n",
        "words2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrGxQh2jY7bj",
        "outputId": "05c52c72-48a6-491a-8850-d703d6bcb058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"hello, i'm Ms.vibha.Studing at DSCE.nder the guidance of Dr.Latha .A.P.Today was a bright day.\\nOn Sunday,Bangalore faced torrentious rain that uprooted several trees,created massive havoc at all places.Few accidents were also seen.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijarBDqsZFUx",
        "outputId": "ffe7887d-8fd3-4b47-f2f2-aff77a6101e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words3=word_tokenize(text)\n",
        "for index,val in enumerate(words3):\n",
        "  print(f'{index}:{val}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93NwqVrfZwkJ",
        "outputId": "3edf096c-40b6-4545-e9a4-941a009c2fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:hello\n",
            "1:,\n",
            "2:i\n",
            "3:'m\n",
            "4:Ms.vibha.Studing\n",
            "5:at\n",
            "6:DSCE.nder\n",
            "7:the\n",
            "8:guidance\n",
            "9:of\n",
            "10:Dr.Latha\n",
            "11:.A.P.Today\n",
            "12:was\n",
            "13:a\n",
            "14:bright\n",
            "15:day\n",
            "16:.\n",
            "17:On\n",
            "18:Sunday\n",
            "19:,\n",
            "20:Bangalore\n",
            "21:faced\n",
            "22:torrentious\n",
            "23:rain\n",
            "24:that\n",
            "25:uprooted\n",
            "26:several\n",
            "27:trees\n",
            "28:,\n",
            "29:created\n",
            "30:massive\n",
            "31:havoc\n",
            "32:at\n",
            "33:all\n",
            "34:places.Few\n",
            "35:accidents\n",
            "36:were\n",
            "37:also\n",
            "38:seen\n",
            "39:.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words4=sent_tokenize(text)\n",
        "\n",
        "for index,val in enumerate(words4):\n",
        "  print(f'{index}:{val}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMjYO28aZ0Jo",
        "outputId": "ae8fedd2-e322-431d-9451-babbb189c218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:hello, i'm Ms.vibha.Studing at DSCE.nder the guidance of Dr.Latha .A.P.Today was a bright day.\n",
            "1:On Sunday,Bangalore faced torrentious rain that uprooted several trees,created massive havoc at all places.Few accidents were also seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(word_tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVE9WKCMaCLJ",
        "outputId": "63a296cb-0f22-4d3e-b863-313b21a233cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function word_tokenize in module nltk.tokenize:\n",
            "\n",
            "word_tokenize(text, language='english', preserve_line=False)\n",
            "    Return a tokenized copy of *text*,\n",
            "    using NLTK's recommended word tokenizer\n",
            "    (currently an improved :class:`.TreebankWordTokenizer`\n",
            "    along with :class:`.PunktSentenceTokenizer`\n",
            "    for the specified language).\n",
            "    \n",
            "    :param text: text to split into words\n",
            "    :type text: str\n",
            "    :param language: the model name in the Punkt corpus\n",
            "    :type language: str\n",
            "    :param preserve_line: A flag to decide whether to sentence tokenize the text or not.\n",
            "    :type preserve_line: bool\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(sent_tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv5acevtaLVq",
        "outputId": "53c8bd86-4c84-4977-859c-ed542d2c5fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sent_tokenize in module nltk.tokenize:\n",
            "\n",
            "sent_tokenize(text, language='english')\n",
            "    Return a sentence-tokenized copy of *text*,\n",
            "    using NLTK's recommended sentence tokenizer\n",
            "    (currently :class:`.PunktSentenceTokenizer`\n",
            "    for the specified language).\n",
            "    \n",
            "    :param text: text to split into sentences\n",
            "    :param language: the model name in the Punkt corpus\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer,WhitespaceTokenizer,WordPunctTokenizer,TweetTokenizer\n"
      ],
      "metadata": {
        "id": "-AhVzRUWaOsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treebankword=TreebankWordTokenizer()\n",
        "words5=treebankword.tokenize(text)\n",
        "for index,val in enumerate(words5):\n",
        "  print(f'{index}:{val}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JcTuA1iaxix",
        "outputId": "0d557c20-ab33-47d2-d48e-4f0de95867fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:hello\n",
            "1:,\n",
            "2:i\n",
            "3:'m\n",
            "4:Ms.vibha.Studing\n",
            "5:at\n",
            "6:DSCE.nder\n",
            "7:the\n",
            "8:guidance\n",
            "9:of\n",
            "10:Dr.Latha\n",
            "11:.A.P.Today\n",
            "12:was\n",
            "13:a\n",
            "14:bright\n",
            "15:day.\n",
            "16:On\n",
            "17:Sunday\n",
            "18:,\n",
            "19:Bangalore\n",
            "20:faced\n",
            "21:torrentious\n",
            "22:rain\n",
            "23:that\n",
            "24:uprooted\n",
            "25:several\n",
            "26:trees\n",
            "27:,\n",
            "28:created\n",
            "29:massive\n",
            "30:havoc\n",
            "31:at\n",
            "32:all\n",
            "33:places.Few\n",
            "34:accidents\n",
            "35:were\n",
            "36:also\n",
            "37:seen\n",
            "38:.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunkt=WordPunctTokenizer()\n",
        "words6=wordpunkt.tokenize(text)\n",
        "for index,val in enumerate(words6):\n",
        "  print(f'{index}:{val}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N1KnZJgbFgC",
        "outputId": "e4027ed1-db6f-4ed7-9215-6aff3632cf52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:hello\n",
            "1:,\n",
            "2:i\n",
            "3:'\n",
            "4:m\n",
            "5:Ms\n",
            "6:.\n",
            "7:vibha\n",
            "8:.\n",
            "9:Studing\n",
            "10:at\n",
            "11:DSCE\n",
            "12:.\n",
            "13:nder\n",
            "14:the\n",
            "15:guidance\n",
            "16:of\n",
            "17:Dr\n",
            "18:.\n",
            "19:Latha\n",
            "20:.\n",
            "21:A\n",
            "22:.\n",
            "23:P\n",
            "24:.\n",
            "25:Today\n",
            "26:was\n",
            "27:a\n",
            "28:bright\n",
            "29:day\n",
            "30:.\n",
            "31:On\n",
            "32:Sunday\n",
            "33:,\n",
            "34:Bangalore\n",
            "35:faced\n",
            "36:torrentious\n",
            "37:rain\n",
            "38:that\n",
            "39:uprooted\n",
            "40:several\n",
            "41:trees\n",
            "42:,\n",
            "43:created\n",
            "44:massive\n",
            "45:havoc\n",
            "46:at\n",
            "47:all\n",
            "48:places\n",
            "49:.\n",
            "50:Few\n",
            "51:accidents\n",
            "52:were\n",
            "53:also\n",
            "54:seen\n",
            "55:.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whitespace=WhitespaceTokenizer()\n",
        "words7=whitespace.tokenize(text)\n",
        "for index,val in enumerate(words7):\n",
        "  print(f'{index}:{val}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXtwzY-Cc7wG",
        "outputId": "34c01ca9-ea07-4534-dbd4-db9a478d8b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:hello,\n",
            "1:i'm\n",
            "2:Ms.vibha.Studing\n",
            "3:at\n",
            "4:DSCE.nder\n",
            "5:the\n",
            "6:guidance\n",
            "7:of\n",
            "8:Dr.Latha\n",
            "9:.A.P.Today\n",
            "10:was\n",
            "11:a\n",
            "12:bright\n",
            "13:day.\n",
            "14:On\n",
            "15:Sunday,Bangalore\n",
            "16:faced\n",
            "17:torrentious\n",
            "18:rain\n",
            "19:that\n",
            "20:uprooted\n",
            "21:several\n",
            "22:trees,created\n",
            "23:massive\n",
            "24:havoc\n",
            "25:at\n",
            "26:all\n",
            "27:places.Few\n",
            "28:accidents\n",
            "29:were\n",
            "30:also\n",
            "31:seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2=\"today is wednesday.Lets make it a bright day bustling with joy.\"\\\n",
        "\"Complete all tasks .Enjoy some free time in between #retrospect #goodlife #dailyliving.\""
      ],
      "metadata": {
        "id": "ZG3mAJlnKcSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweetTokenizer=TweetTokenizer()\n",
        "words8=tweetTokenizer.tokenize(text2)\n",
        "words8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzIrIIeTK2Lu",
        "outputId": "537ac355-2081-4dc4-a5fa-4fe3d6e8ed5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['today',\n",
              " 'is',\n",
              " 'wednesday.Lets',\n",
              " 'make',\n",
              " 'it',\n",
              " 'a',\n",
              " 'bright',\n",
              " 'day',\n",
              " 'bustling',\n",
              " 'with',\n",
              " 'joy.Complete',\n",
              " 'all',\n",
              " 'tasks',\n",
              " '.',\n",
              " 'Enjoy',\n",
              " 'some',\n",
              " 'free',\n",
              " 'time',\n",
              " 'in',\n",
              " 'between',\n",
              " '#retrospect',\n",
              " '#goodlife',\n",
              " '#dailyliving',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import PunktSentenceTokenizer,RegexpTokenizer,LineTokenizer,BlanklineTokenizer,TreebankWordDetokenizer"
      ],
      "metadata": {
        "id": "XMIQaOVLPJb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text3=\"Stars are beautiful things.\"\\\n",
        "\"they emit radiations.\"\\\n",
        "\"sun is the powerful star in solar system.\"\\\n",
        "\"it has hydrogen and helium reacting with each other 24\\7.\"\\\n",
        "\"it the the ultimate source of energy to all beings on earth.\""
      ],
      "metadata": {
        "id": "DzpUNKYNPdEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punkt_token=PunktSentenceTokenizer()#no pre training\n",
        "words9=punkt_token.tokenize(text3)\n",
        "for index,token in enumerate(words9):\n",
        "  print(f'{index}:{token}')#less accurate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yacsALdjP9EM",
        "outputId": "baa6ecad-3bc5-4be3-8e4b-5e8258ae557d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:Stars are beautiful things.they emit radiations.sun is the powerful star in solar system.it has hydrogen and helium reacting with each other 24\u0007.it the the ultimate source of energy to all beings on earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "punkt_token=PunktSentenceTokenizer(words9)#with pre training\n",
        "words9=punkt_token.tokenize(text3)\n",
        "for index,token in enumerate(words9):\n",
        "  print(f'{index}:{token}')#more accurate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs6tOddaQhVH",
        "outputId": "971788a2-b136-4b2e-b6b6-7ae680804702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:Stars are beautiful things.they emit radiations.sun is the powerful star in solar system.it has hydrogen and helium reacting with each other 24\u0007.it the the ultimate source of energy to all beings on earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_token=RegexpTokenizer(r'/[a-z A-Z][0-9]/',text3)\n",
        "words10=reg_token.tokenize(text3)\n",
        "for index,token in enumerate(words10):\n",
        "  print(f'{index}:{token}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oam8I9MoQva6",
        "outputId": "78ffa0a7-11df-4a4f-c65d-9a01d651f51a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:Stars are beautiful things.they emit radiations.sun is the powerful star in solar system.it has hydrogen and helium reacting with each other 24\u0007.it the the ultimate source of energy to all beings on earth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text4='''\n",
        "Stars are beautiful things.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "they emit radiations.\n",
        "\n",
        "\n",
        "sun is the powerful star in solar system.\n",
        "\n",
        "\n",
        "it has hydrogen and helium reacting with each other 24\\7.\n",
        "'''\n",
        "text4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5Hetzo5YRJwa",
        "outputId": "a8139e5e-b9ce-47d0-c571-4fe0f72e6fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nStars are beautiful things.\\n\\n\\n\\n\\nthey emit radiations.\\n\\n\\nsun is the powerful star in solar system.\\n\\n\\nit has hydrogen and helium reacting with each other 24\\x07.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line_token=LineTokenizer()\n",
        "words11=line_token.tokenize(text4)\n",
        "for index,token in enumerate(words11):\n",
        "  print(f'{index}:{token}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ45oV9kRc1i",
        "outputId": "19a7924f-9cec-4fa7-bba1-3b6e0db0f25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:Stars are beautiful things.\n",
            "1:they emit radiations.\n",
            "2:sun is the powerful star in solar system.\n",
            "3:it has hydrogen and helium reacting with each other 24\u0007.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blankline_token=BlanklineTokenizer()\n",
        "words12=reg_token.tokenize(text4)\n",
        "for index,token in enumerate(words12):\n",
        "  print(f'{index}:{token}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V1-NDm_Rn3p",
        "outputId": "1a76e9de-9c16-440f-8993-8df2d4d18680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\n",
            "Stars are beautiful things.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "they emit radiations.\n",
            "\n",
            "\n",
            "sun is the powerful star in solar system.\n",
            "\n",
            "\n",
            "it has hydrogen and helium reacting with each other 24\u0007.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "de_token=TreebankWordDetokenizer()\n",
        "text5=de_token.tokenize(words5)\n",
        "for index,token in enumerate(text5):\n",
        "  print(f'{index}:{token}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrXOzZ-0R3Ql",
        "outputId": "08933f4f-2273-4f94-c43e-fe7ef64bd648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:h\n",
            "1:e\n",
            "2:l\n",
            "3:l\n",
            "4:o\n",
            "5:,\n",
            "6: \n",
            "7:i\n",
            "8:'\n",
            "9:m\n",
            "10: \n",
            "11:M\n",
            "12:s\n",
            "13:.\n",
            "14:v\n",
            "15:i\n",
            "16:b\n",
            "17:h\n",
            "18:a\n",
            "19:.\n",
            "20:S\n",
            "21:t\n",
            "22:u\n",
            "23:d\n",
            "24:i\n",
            "25:n\n",
            "26:g\n",
            "27: \n",
            "28:a\n",
            "29:t\n",
            "30: \n",
            "31:D\n",
            "32:S\n",
            "33:C\n",
            "34:E\n",
            "35:.\n",
            "36:n\n",
            "37:d\n",
            "38:e\n",
            "39:r\n",
            "40: \n",
            "41:t\n",
            "42:h\n",
            "43:e\n",
            "44: \n",
            "45:g\n",
            "46:u\n",
            "47:i\n",
            "48:d\n",
            "49:a\n",
            "50:n\n",
            "51:c\n",
            "52:e\n",
            "53: \n",
            "54:o\n",
            "55:f\n",
            "56: \n",
            "57:D\n",
            "58:r\n",
            "59:.\n",
            "60:L\n",
            "61:a\n",
            "62:t\n",
            "63:h\n",
            "64:a\n",
            "65: \n",
            "66:.\n",
            "67:A\n",
            "68:.\n",
            "69:P\n",
            "70:.\n",
            "71:T\n",
            "72:o\n",
            "73:d\n",
            "74:a\n",
            "75:y\n",
            "76: \n",
            "77:w\n",
            "78:a\n",
            "79:s\n",
            "80: \n",
            "81:a\n",
            "82: \n",
            "83:b\n",
            "84:r\n",
            "85:i\n",
            "86:g\n",
            "87:h\n",
            "88:t\n",
            "89: \n",
            "90:d\n",
            "91:a\n",
            "92:y\n",
            "93:.\n",
            "94: \n",
            "95:O\n",
            "96:n\n",
            "97: \n",
            "98:S\n",
            "99:u\n",
            "100:n\n",
            "101:d\n",
            "102:a\n",
            "103:y\n",
            "104:,\n",
            "105: \n",
            "106:B\n",
            "107:a\n",
            "108:n\n",
            "109:g\n",
            "110:a\n",
            "111:l\n",
            "112:o\n",
            "113:r\n",
            "114:e\n",
            "115: \n",
            "116:f\n",
            "117:a\n",
            "118:c\n",
            "119:e\n",
            "120:d\n",
            "121: \n",
            "122:t\n",
            "123:o\n",
            "124:r\n",
            "125:r\n",
            "126:e\n",
            "127:n\n",
            "128:t\n",
            "129:i\n",
            "130:o\n",
            "131:u\n",
            "132:s\n",
            "133: \n",
            "134:r\n",
            "135:a\n",
            "136:i\n",
            "137:n\n",
            "138: \n",
            "139:t\n",
            "140:h\n",
            "141:a\n",
            "142:t\n",
            "143: \n",
            "144:u\n",
            "145:p\n",
            "146:r\n",
            "147:o\n",
            "148:o\n",
            "149:t\n",
            "150:e\n",
            "151:d\n",
            "152: \n",
            "153:s\n",
            "154:e\n",
            "155:v\n",
            "156:e\n",
            "157:r\n",
            "158:a\n",
            "159:l\n",
            "160: \n",
            "161:t\n",
            "162:r\n",
            "163:e\n",
            "164:e\n",
            "165:s\n",
            "166:,\n",
            "167: \n",
            "168:c\n",
            "169:r\n",
            "170:e\n",
            "171:a\n",
            "172:t\n",
            "173:e\n",
            "174:d\n",
            "175: \n",
            "176:m\n",
            "177:a\n",
            "178:s\n",
            "179:s\n",
            "180:i\n",
            "181:v\n",
            "182:e\n",
            "183: \n",
            "184:h\n",
            "185:a\n",
            "186:v\n",
            "187:o\n",
            "188:c\n",
            "189: \n",
            "190:a\n",
            "191:t\n",
            "192: \n",
            "193:a\n",
            "194:l\n",
            "195:l\n",
            "196: \n",
            "197:p\n",
            "198:l\n",
            "199:a\n",
            "200:c\n",
            "201:e\n",
            "202:s\n",
            "203:.\n",
            "204:F\n",
            "205:e\n",
            "206:w\n",
            "207: \n",
            "208:a\n",
            "209:c\n",
            "210:c\n",
            "211:i\n",
            "212:d\n",
            "213:e\n",
            "214:n\n",
            "215:t\n",
            "216:s\n",
            "217: \n",
            "218:w\n",
            "219:e\n",
            "220:r\n",
            "221:e\n",
            "222: \n",
            "223:a\n",
            "224:l\n",
            "225:s\n",
            "226:o\n",
            "227: \n",
            "228:s\n",
            "229:e\n",
            "230:e\n",
            "231:n\n",
            "232:.\n"
          ]
        }
      ]
    }
  ]
}